{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport h5py\nimport matplotlib\nfrom scipy import signal\nfrom matplotlib import pyplot as plt\n# %matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Keras\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras import regularizers\nfrom tqdm import tqdm\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\n# Custom imports\nimport scipy.io\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"../input/dataLabel.p\", 'rb') as f:\n  label_dict, enc_dict = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a6525aec48fa235da63ea448125d3259d11db11"},"cell_type":"code","source":"import pickle\nwith open(\"../input/fullData.p\", 'rb') as f:\n  lengths, ecgData, ecgKeys = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ab141a36ea26003a6f01e681c166a482fb8a2a6"},"cell_type":"code","source":"import numpy as np\nfrom scipy import signal\nimport scipy as sc\n\ndef extend_ts(ts, length):\n    extended = np.zeros(length)\n    siglength = np.min([length, ts.shape[0]])\n    extended[:siglength] = ts[:siglength]\n    return extended \n\ndef zero_filter(input, threshold=2, depth=8):\n    shape = input.shape\n    # compensate for lost length due to mask processing\n    noise_shape = [shape[0], shape[1] + depth]\n    \n    # Generate random noise\n    noise = np.random.normal(0,1,noise_shape)\n    \n    # Pick positions where the noise is above a certain threshold\n    mask = np.greater(noise, threshold)\n    \n    # grow a neighbourhood of True values with at least length depth+1\n    for d in range(depth):\n        mask = np.logical_or(mask[:, :-1], mask[:, 1:])\n    output = np.where(mask, np.zeros(shape), input)\n    return output\n\ndef stretch_squeeze(source, length):\n    target = np.zeros([1, length])\n    interpol_obj = sc.interpolate.interp1d(np.arange(source.size), source)\n    grid = np.linspace(0, source.size - 1, target.size)\n    result = interpol_obj(grid)\n    return result\n\ndef fit_tolength(source, length):\n    target = np.zeros([length])\n    w_l = min(source.size, target.size)\n    target[0:w_l] = source[0:w_l]\n    return target\n\n# Data augmentation scheme: Random resampling\ndef random_resample(signals, upscale_factor = 1):\n    [n_signals,length] = signals.shape\n    # pulse variation from 60 bpm to 120 bpm, expected 80 bpm\n    new_length = np.random.randint(\n        low=int(length*80/120),\n        high=int(length*80/60),\n        size=[n_signals, upscale_factor])\n    signals = [np.array(s) for s in signals.tolist()]\n    new_length = [np.array(nl) for nl in new_length.tolist()]\n    sigs = [stretch_squeeze(s,l) for s,nl in zip(signals,new_length) for l in nl]\n    sigs = [fit_tolength(s, length) for s in sigs]\n    sigs = np.array(sigs)\n    return sigs\n\ndef spectrogram(data, nperseg=64, noverlap=32, log_spectrogram = True, fs=300):\n    f, t, Sxx = signal.spectrogram(data, fs=fs, nperseg=nperseg, noverlap=noverlap)\n#     print(Sxx.shape)\n    Sxx = np.transpose(Sxx,[0,2,1])\n    if log_spectrogram:\n        Sxx = abs(Sxx) # Make sure, all values are positive before taking log\n        mask = Sxx > 0 # We dont want to take the log of zero\n        Sxx[mask] = np.log(Sxx[mask])\n    return f, t, Sxx\n\n# Spectrogram statistics needed for normalization of the data set\ndef transformed_stats(ecgData, ecgKeys, nperseg, noverlap, sequence_length):\n\n    ''' Gets some important statistics of the spectrograms in the entire dataset.\n    We need this to rescale the data'''\n\n    dataset_list = ecgKeys\n    sample_list = []\n\n    for dataset in dataset_list:\n        data = extend_ts(ecgData[dataset], sequence_length)\n        data = np.reshape(data, (1, len(data)))\n        sample_list.append(np.expand_dims(spectrogram(data, nperseg, noverlap)[2], axis = 3))\n    \n    sample_array = np.vstack(sample_list)\n    \n    #Flatten the array so that we can do statistics\n    samples = np.ndarray.flatten(sample_array)\n        \n    return np.min(samples), np.max(samples), np.mean(samples), np.std(samples)\n\n# Float types are normalized to zero mean std \ndef norm_float(data, data_mean, data_std):\n    scaled = (data - data_mean)/data_std\n    return scaled\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc1a126b4e6ddb09689e6b141f472b28e6d7e31d"},"cell_type":"code","source":"import numpy as np\nimport keras\n\n\ndef generator(ecgData, ecgKeys, label_dict, batch_size = 32, dim = (178, 33), \n                 nperseg = 64, noverlap = 32, data_mean = -9.01, data_std = 9.00,  \n                 n_channels=1, sequence_length = 5736, \n                 n_classes = 4, shuffle = True, augment = False):\n    while True:\n        X = np.empty((batch_size, dim[0], dim[1], n_channels), dtype = float)\n        y = np.empty((batch_size), dtype = int)\n\n        randomIds = np.random.randint(0, len(ecgKeys), batch_size)\n\n        for i, ID in enumerate(randomIds):\n            data = extend_ts(ecgData[ecgKeys[ID]], sequence_length)\n            data = np.reshape(data, (1, len(data)))\n\n            if augment:\n\n                # dropout bursts\n                data = zero_filter(data, threshold = 2, depth = 10)\n\n                # random resampling\n                data = random_resample(data)\n\n            # Generate spectrogram\n            data_spectrogram = spectrogram(data, nperseg = nperseg, noverlap = noverlap)[2]\n\n            # Normalize\n            data_transformed = norm_float(data_spectrogram, data_mean, data_std)\n\n            X[i,] = np.expand_dims(data_transformed, axis = 3)\n\n            # Assuming that the dataset names are unique (only 1 per label)\n            y[i] = label_dict[ecgKeys[ID]]\n\n        yield X, keras.utils.to_categorical(y, num_classes=n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8462abb3081d987990b989e70898a108344e0f9f"},"cell_type":"code","source":"# Spectrogram Parameters\nFs = 300\nNFFT = 64\nNOVERLAP = 32\nN_classes = 4\nBATCH_SIZE = 32\nMAX_LENGTH = 9000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"014f205041b6a6f38e7e6782756df20b93710aa9"},"cell_type":"code","source":"_, _, Sxx = spectrogram(ecgData[ecgKeys[0]].reshape(1, 9000), nperseg = NFFT, noverlap = NOVERLAP)\nDIM = Sxx[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34f2f58e7664b0f3ba59307b8802cc68605746b2"},"cell_type":"code","source":"MIN, MAX, MEAN, STD = transformed_stats(ecgData, ecgKeys, NFFT, NOVERLAP, MAX_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25e08d9f0db1b3db1b56950f8b7fc47a5ce1083f"},"cell_type":"code","source":"gen = generator(ecgData, ecgKeys, label_dict, augment=True,batch_size=32, dim=DIM, nperseg=NFFT, noverlap=NOVERLAP, data_mean=MEAN, data_std=STD, n_channels=1, sequence_length=9000, n_classes=4, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdf329fe93fa8af0b157be6684c0700a6a884001"},"cell_type":"code","source":"# Convolutional blocks\ndef conv2d_block(model, depth, layer_filters, filters_growth, \n                 strides_start, strides_end, input_shape, first_layer = False):\n    \n    ''' Convolutional block. \n    depth: number of convolutional layers in the block (4)\n    filters: 2D kernel size (32)\n    filters_growth: kernel size increase at the end of block (32)\n    first_layer: provide input_shape for first layer'''\n    \n    # Fixed parameters for convolution\n    conv_parms = {'kernel_size': (3, 3),\n                  'padding': 'same',\n                  'dilation_rate': (1, 1),\n                  'activation': None,\n                  'data_format': 'channels_last',\n                  'kernel_initializer': 'glorot_normal'}\n\n    for l in range(depth):\n\n        if first_layer:\n            \n            # First layer needs an input_shape \n            model.add(layers.Conv2D(filters = layer_filters,\n                                    strides = strides_start,\n                                    input_shape = input_shape, **conv_parms))\n            first_layer = False\n        \n        else:\n            # All other layers will not need an input_shape parameter\n            if l == depth - 1:\n                # Last layer in each block is different: adding filters and using stride 2\n                layer_filters += filters_growth\n                model.add(layers.Conv2D(filters = layer_filters,\n                                        strides = strides_end, **conv_parms))\n            else:\n                model.add(layers.Conv2D(filters = layer_filters,\n                                        strides = strides_start, **conv_parms))\n        \n        # Continue with batch normalization and activation for all layers in the block\n        model.add(layers.BatchNormalization(center = True, scale = True))\n        model.add(layers.Activation('relu'))\n    \n    return model\n\ndef MeanOverTime():\n    lam_layer = layers.Lambda(lambda x: K.mean(x, axis=1), output_shape=lambda s: (1, s[2]))\n    return lam_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d8d1f6bf87f54a8445ef1762318738870dd9cc"},"cell_type":"code","source":"# Define the model\n# Model parameters\nfilters_start = 32 # Number of convolutional filters\nlayer_filters = filters_start # Start with these filters\nfilters_growth = 32 # Filter increase after each convBlock\nstrides_start = (1, 1) # Strides at the beginning of each convBlock\nstrides_end = (2, 2) # Strides at the end of each convBlock\ndepth = 4 # Number of convolutional layers in each convBlock\nn_blocks = 6 # Number of ConBlocks\nn_channels = 1 # Number of color channgels\ninput_shape = (280, 33, 1) # input shape for first layer\n\n\nmodel = Sequential()\n\nfor block in range(n_blocks):\n\n    # Provide input only for the first layer\n    if block == 0:\n        provide_input = True\n    else:\n        provide_input = False\n    \n    model = conv2d_block(model, depth,\n                         layer_filters,\n                         filters_growth,\n                         strides_start, strides_end,\n                         input_shape,\n                         first_layer = provide_input)\n    \n    # Increase the number of filters after each block\n    layer_filters += filters_growth\n\n\n\n# Remove the frequency dimension, so that the output can feed into LSTM\n# Reshape to (batch, time steps, filters)\nmodel.add(layers.Reshape((-1, 224)))\nmodel.add(layers.core.Masking(mask_value = 0.0))\nmodel.add(MeanOverTime())\n\n# Alternative: Replace averaging by LSTM\n\n# Insert masking layer to ignore zeros\n#model.add(layers.core.Masking(mask_value = 0.0))\n\n# Add LSTM layer with 3 neurons\n#model.add(layers.LSTM(200))\n#model.add(layers.Flatten())\n\n# And a fully connected layer for the output\nmodel.add(layers.Dense(4, activation='sigmoid', kernel_regularizer = regularizers.l2(0.1)))\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab50671c5df11c0cc9e09ef540848562a1c50ba7"},"cell_type":"code","source":"model = keras.models.load_model(\"../input/modelCNN (1).h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b23112f9d1ed84a4611841bb68884b47b018b3d"},"cell_type":"code","source":"# Compile the model and run a batch through the network\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.000001, decay=0.09),\n              metrics=['acc'])\n\nmodel_checkpoint = ModelCheckpoint(\"modelCNN.h5\", save_best_only=False, save_weights_only=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e15c4f39950228290f5f3bcff6224605fbbb4bb4"},"cell_type":"code","source":"model.fit_generator(gen,steps_per_epoch = 800,epochs = 100, callbacks=[model_checkpoint])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}